# Rosenbrock GBDT模型架构与实现

## 模型概述

Rosenbrock GBDT模型是一个基于梯度提升决策树(Gradient Boosting Decision Tree)的回归模型，主要用于预测Rosenbrock函数的输出值。该模型利用scikit-learn的GradientBoostingRegressor实现，并通过Optuna框架进行贝叶斯优化调参，以提高预测性能。

## 数据集说明

该模型使用的数据集是Rosenbrock函数生成的数据：
- 输入特征：多维空间中的点坐标（x₁, x₂, ...）
- 输出目标：对应点的Rosenbrock函数值

数据集文件包括：
- `Rosenbrock_x_train.npy`：训练集特征
- `Rosenbrock_y_train.npy`：训练集标签
- `Rosenbrock_x_test.npy`：测试集特征
- `Rosenbrock_y_test.npy`：测试集标签

## 模型架构

### 基本架构

模型基于梯度提升决策树(GBDT)实现，核心是scikit-learn的`GradientBoostingRegressor`。GBDT是一种集成学习方法，通过顺序构建多个决策树，每棵树都试图纠正前一棵树的误差，从而逐步提升预测性能。

### 关键参数

GBDT模型的关键参数包括：

```python
# 模型定义示例
model = GradientBoostingRegressor(
    n_estimators=300,       # 树的数量
    learning_rate=0.1,      # 学习率
    max_depth=5,            # 树的最大深度
    min_samples_split=5,    # 分裂内部节点所需的最小样本数
    min_samples_leaf=2,     # 叶节点所需的最小样本数
    subsample=0.8,          # 训练每棵树使用的样本比例
    max_features='sqrt',    # 寻找最佳分裂时考虑的特征数量
    random_state=42         # 随机种子
)
```

### 超参数调优

模型使用Optuna框架实现贝叶斯优化，对以下超参数进行搜索：

```python
# 超参数搜索空间
param_space = {
    'n_estimators': (100, 500),           # 树的数量范围
    'learning_rate': (0.01, 0.3),         # 学习率范围
    'max_depth': (3, 10),                 # 树的最大深度范围
    'min_samples_split': (2, 20),         # 内部节点分裂所需最小样本数范围
    'min_samples_leaf': (1, 10),          # 叶节点所需最小样本数范围
    'subsample': (0.6, 1.0),              # 样本比例范围
    'max_features': ['sqrt', 'log2', None] # 特征选择方法
}
```

## 评估指标

模型使用多个指标进行评估：
1. **均方误差(MSE)**：主要优化目标
2. **Pearson相关系数**：目标达到 >= 0.85
3. **决定系数(R²)**：评估模型解释方差的能力

## 代码实现

### 数据加载与预处理

```python
# 数据加载函数
def load_data(data_dir: str = None) -> Dict[str, np.ndarray]:
    """加载Rosenbrock数据集"""
    # 加载训练集
    X_train = np.load(os.path.join(data_dir, 'Rosenbrock_x_train.npy'))
    y_train = np.load(os.path.join(data_dir, 'Rosenbrock_y_train.npy'))
    
    # 加载测试集
    X_test = np.load(os.path.join(data_dir, 'Rosenbrock_x_test.npy'))
    y_test = np.load(os.path.join(data_dir, 'Rosenbrock_y_test.npy'))
    
    return {
        'X_train': X_train,
        'y_train': y_train,
        'X_test': X_test,
        'y_test': y_test
    }

# 数据预处理函数
def preprocess_data(data: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:
    """预处理Rosenbrock数据集"""
    # 复制数据以避免修改原始数据
    processed_data = {
        'X_train': data['X_train'].copy(),
        'y_train': data['y_train'].copy(),
        'X_test': data['X_test'].copy(),
        'y_test': data['y_test'].copy()
    }
    
    # 检查是否有缺失值
    for key, array in processed_data.items():
        if np.isnan(array).any():
            processed_data[key] = np.nan_to_num(array, nan=0.0)
    
    # 注意：GBDT对特征缩放不敏感，所以不进行标准化
    return processed_data
```

### 贝叶斯优化实现

```python
def bayesian_optimization(data: Dict[str, np.ndarray], 
                         n_trials: int = 50,
                         timeout: Optional[int] = None,
                         use_gpu: bool = False,
                         random_state: int = 42) -> Dict[str, Any]:
    """使用贝叶斯优化进行超参数优化"""
    # 创建优化器
    study = optuna.create_study(
        direction='maximize',  # 因为返回负MSE，所以是最大化
        sampler=optuna.samplers.TPESampler(seed=random_state)
    )
    
    # 开始优化
    study.optimize(
        lambda trial: optuna_objective(trial, data, random_state),
        n_trials=n_trials,
        timeout=timeout,
        catch=(Exception,)
    )
    
    # 获取最佳参数
    best_params = study.best_params
    
    # 使用最佳参数训练最终模型
    best_model = GradientBoostingRegressor(
        **best_params,
        random_state=random_state
    )
    
    best_model.fit(data['X_train'], data['y_train'])
    
    return {
        'best_model': best_model,
        'best_params': best_params,
        'best_score': -study.best_value,  # 转换回正的MSE值
        'study': study,
        # ... 其他返回值
    }
```

### 目标函数定义

```python
def optuna_objective(trial, data: Dict[str, np.ndarray], random_state: int = 42) -> float:
    """Optuna目标函数，使用MSE作为损失函数"""
    # 获取参数
    params = {
        'n_estimators': trial.suggest_int('n_estimators', 100, 500),
        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),
        'max_depth': trial.suggest_int('max_depth', 3, 10),
        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),
        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),
        'subsample': trial.suggest_float('subsample', 0.6, 1.0),
        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),
        'random_state': random_state
    }
    
    # 使用K折交叉验证
    kf = KFold(n_splits=5, shuffle=True, random_state=random_state)
    mse_scores = []
    pearson_scores = []
    r2_scores = []
    
    for train_idx, val_idx in kf.split(data['X_train']):
        X_fold_train, X_fold_val = data['X_train'][train_idx], data['X_train'][val_idx]
        y_fold_train, y_fold_val = data['y_train'][train_idx], data['y_train'][val_idx]
        
        # 训练模型
        model = GradientBoostingRegressor(**params)
        model.fit(X_fold_train, y_fold_train)
        
        # 预测并计算指标
        y_pred = model.predict(X_fold_val)
        mse = mean_squared_error(y_fold_val, y_pred)
        pearson = pearsonr(y_fold_val, y_pred)[0]
        r2 = r2_score(y_fold_val, y_pred)
        
        mse_scores.append(mse)
        pearson_scores.append(pearson)
        r2_scores.append(r2)
    
    # 计算平均分数
    mean_mse = np.mean(mse_scores)
    mean_pearson = np.mean(pearson_scores)
    mean_r2 = np.mean(r2_scores)
    
    # 记录Pearson相关系数到trial的用户属性中
    trial.set_user_attr('pearson', mean_pearson)
    trial.set_user_attr('r2', mean_r2)
    
    return -mean_mse  # 返回负MSE，因为Optuna默认是最大化目标
```

## 模型训练流程

完整的模型训练流程如下：

1. 加载数据：`data = load_data()`
2. 预处理数据：`processed_data = preprocess_data(data)`
3. 贝叶斯优化：`results = bayesian_optimization(processed_data, n_trials=50)`
4. 评估最佳模型：在测试集上计算MSE、Pearson相关系数和R²
5. 可视化结果：生成特征重要性、预测分析、残差分析等图表
6. 保存模型：保存最佳模型和参数

## 变量说明

在代码中的主要变量含义：
- `X_train`, `X_test`：训练集和测试集的特征矩阵，形状为(n_samples, n_features)
- `y_train`, `y_test`：训练集和测试集的目标值，形状为(n_samples,)
- `n_estimators`：GBDT模型中决策树的数量
- `learning_rate`：学习率，控制每棵树的贡献权重
- `max_depth`：每棵决策树的最大深度
- `min_samples_split`：分裂内部节点所需的最小样本数
- `min_samples_leaf`：叶节点所需的最小样本数
- `subsample`：训练每棵树时使用的训练样本比例（<1.0表示随机子采样）
- `max_features`：寻找最佳分裂时考虑的特征数量或比例
- `random_state`：随机种子，确保结果可复现

## 模型评估结果解释

- **MSE (均方误差)**：数值越小表示预测越准确
- **Pearson相关系数**：接近1表示预测值与实际值高度正相关
- **R²**：接近1表示模型可以解释大部分方差

模型的目标是达到Pearson相关系数 >= 0.85，这表示模型预测值与真实值之间具有很强的线性相关性。
